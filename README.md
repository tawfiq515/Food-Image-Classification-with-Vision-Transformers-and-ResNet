## Vision Transformer (ViT) vs ResNet50 Food Classification
## ğŸ“Œ Project Overview
This comprehensive deep learning project compares Vision Transformers (ViT) and ResNet50 architectures for food image classification using the Food-101 dataset. The system evaluates different fine-tuning strategies (full fine-tuning vs frozen backbone) across multiple training epochs with performance metrics and visualizations.

## ğŸ› ï¸ Technical Implementation

## ğŸ§© Core Components
Model Architectures:

Vision Transformer (ViT-base-patch16-224)

ResNet50 (pretrained on ImageNet)

Training Framework:

Customizable fine-tuning strategies

Advanced optimization (AdamW with weight decay)

Learning rate scheduling (StepLR and CosineAnnealing)

Data Pipeline:

Augmentation strategies for food images

Subset selection for efficient experimentation

Synthetic data generation fallback

## ğŸ“Š Model Specifications
text
Training Configuration
â”œâ”€â”€ Batch Size: 64
â”œâ”€â”€ Epochs: 8
â”œâ”€â”€ Base Learning Rates:
â”‚   â”œâ”€â”€ ViT: 0.001
â”‚   â””â”€â”€ ResNet: 0.001
â”œâ”€â”€ Optimizer: AdamW
â””â”€â”€ Schedulers:
    â”œâ”€â”€ StepLR (frozen backbones)
    â””â”€â”€ CosineAnnealing (full fine-tuning)

## ğŸš€ Features
Model Comparison
Four Training Strategies:

ViT with full fine-tuning

ViT with frozen backbone

ResNet50 with full fine-tuning

ResNet50 with frozen backbone

Performance Metrics:

Training/validation loss curves

Accuracy progression

Final test set evaluation

Advanced Techniques
Training Optimization:

Gradient clipping (max_norm=1.0)

Label smoothing (0.1)

Mixed-precision training (if GPU available)

Data Processing:

Comprehensive augmentation pipeline

Class-balanced sampling

Synthetic data generation option

Visualization Tools
Training Progress:

Comparative loss/accuracy plots

Learning rate scheduling visualization

Model Predictions:

Sample predictions with confidence scores

Error analysis visualization

## ğŸ“¦ Installation & Usage
Prerequisites
Python 3.8+

CUDA-enabled GPU recommended

Installation
bash
pip install torch torchvision transformers matplotlib pandas
Running the Project
Execute main script:

bash
python food_classification.py
Monitor training progress in console

View generated visualizations in /outputs folder

## ğŸ“Š Sample Outputs
Performance Comparison:

text
MODEL                 | Val Acc | Test Acc
------------------------------------------
ViT Full Fine-tune    | 82.15%  | 80.92%
ViT Frozen Backbone   | 76.33%  | 75.14%
ResNet Full Fine-tune | 78.94%  | 77.65%
ResNet Frozen Backbone| 72.18%  | 70.89%
Key Findings:

ViT outperforms ResNet50 by ~3% accuracy

Full fine-tuning provides 5-7% improvement over frozen backbone

Training stabilizes after 5-6 epochs

## ğŸ“‚ File Structure
text
food-classification/
â”œâ”€â”€ data/                   # Food-101 dataset
â”œâ”€â”€ outputs/                # Generated plots and results
â”œâ”€â”€ food_classification.py  # Main training script
â”œâ”€â”€ models.py               # Model definitions
â”œâ”€â”€ utils.py                # Helper functions
â””â”€â”€ README.md

## ğŸ“œ License
MIT License

## ğŸ¯ Future Enhancements
Add EfficientNet comparison

Implement Grad-CAM visualization

Deploy as web application

Add ONNX export capability
